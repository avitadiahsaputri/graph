/**
 * @module teams-ai
 */
/**
 * Copyright (c) Microsoft Corporation. All rights reserved.
 * Licensed under the MIT License.
 */
import { Planner, Plan } from './Planner';
import { TurnState } from './TurnState';
import { DefaultTurnState } from './DefaultTurnStateManager';
import { TurnContext } from 'botbuilder';
import { OpenAIClient } from './OpenAIClients';
import { ConfiguredAIOptions } from './AI';
import { PromptTemplate } from './Prompts';
/**
 * Options for the OpenAI based planner.
 */
export interface OpenAIPlannerOptions {
    /**
     * OpenAI API key.
     */
    apiKey: string;
    /**
     * Optional. OpenAI organization.
     */
    organization?: string;
    /**
     * Optional. OpenAI endpoint.
     */
    endpoint?: string;
    /**
     * The default model to use.
     * @summary
     * Prompts can override this model.
     */
    defaultModel: string;
    /**
     * Optional. A flag indicating if the planner should only say one thing per turn.
     * @summary
     * The planner will attempt to combine multiple SAY commands into a single SAY command when true.
     * Defaults to false.
     */
    oneSayPerTurn?: boolean;
    /**
     * Optional. A flag indicating if the planner should use the 'system' role when calling OpenAI's
     * chatCompletion API.
     * @summary
     * The planner current uses the 'user' role by default as this tends to generate more reliable
     * instruction following. Defaults to false.
     */
    useSystemMessage?: boolean;
    /**
     * Optional. A flag indicating if the planner should log requests to the console.
     * @summary
     * Both the prompt text and the completion response will be logged to the console. For
     * chatCompletion calls the outgoing messages array will also be logged.
     * Defaults to false.
     */
    logRequests?: boolean;
}
/**
 * A planner that uses OpenAI's textCompletion and chatCompletion API's to generate plans.
 * @summary
 * This planner can be configured to use different models for different prompts. The prompts model
 * will determine which API is used to generate the plan. Any model that starts with 'gpt-' will
 * use the chatCompletion API, otherwise the textCompletion API will be used.
 * @template TState Optional. Type of the applications turn state.
 * @template TOptions Optional. Type of the planner options.
 */
export declare class OpenAIPlanner<TState extends TurnState = DefaultTurnState, TOptions extends OpenAIPlannerOptions = OpenAIPlannerOptions> implements Planner<TState> {
    private readonly _options;
    private readonly _client;
    /**
     * Creates a new instance of the OpenAI based planner.
     * @param {TOptions} options Options for the OpenAI based planner.
     */
    constructor(options: TOptions);
    /**
     * @returns {TOptions} Returns the configured options for the planner.
     */
    get options(): TOptions;
    /**
     * Completes a prompt without returning a plan.
     * @param {TurnContext} context Context for the current turn of conversation.
     * @param {TState} state Application state for the current turn of conversation.
     * @param {PromptTemplate} prompt Prompt to complete.
     * @param {ConfiguredAIOptions<TState>} options Configuration options for the AI system.
     * @returns {Promise<string>} The response from the prompt. Can return undefined to indicate the prompt was rate limited.
     */
    completePrompt(context: TurnContext, state: TState, prompt: PromptTemplate, options: ConfiguredAIOptions<TState>): Promise<string>;
    /**
     * Completes a prompt and generates a plan for the AI system to execute.
     * @param {TurnContext} context Context for the current turn of conversation.
     * @param {TState} state Application state for the current turn of conversation.
     * @param {PromptTemplate} prompt Prompt to complete.
     * @param {ConfiguredAIOptions<TState>} options Configuration options for the AI system.
     * @returns {Promise<Plan>} The plan that was generated.
     */
    generatePlan(context: TurnContext, state: TState, prompt: PromptTemplate, options: ConfiguredAIOptions<TState>): Promise<Plan>;
    /**
     * Creates a new OpenAI client with the provided options.
     * @param {TOptions} options The options to use when creating the client.
     * @returns {OpenAIClient} The newly created OpenAI client.
     */
    protected createClient(options: TOptions): OpenAIClient;
    /**
     * Returns the model to use for the given prompt.
     * @param {PromptTemplate} prompt The prompt to get the model for.
     * @returns {string} The model to use for the given prompt.
     */
    private getModel;
    /**
     * Creates a chat completion request for the given prompt and user message.
     * @param {TState} state Application state for the current turn of conversation.
     * @param {PromptTemplate} prompt Prompt to complete.
     * @param {string} userMessage The user's message to include in the chat completion request.
     * @param {ConfiguredAIOptions<TState>} options Configuration options for the AI system.
     * @returns {CreateChatCompletionRequest} The chat completion request that was generated.
     * @private
     */
    private createChatCompletionRequest;
    /**
     * Creates a completion request for the given prompt.
     * @param {PromptTemplate} prompt The prompt to create the completion request for.
     * @returns {CreateCompletionRequest} The completion request that was generated.
     * @private
     */
    private createCompletionRequest;
    /**
     * @param {any} request The request to patch stop sequences for.
     * @private
     */
    private patchStopSequences;
    /**
     * Creates a chat completion request for the given prompt and user message.
     * @param {CreateChatCompletionRequest} request The request to create a chat completion for.
     * @returns {Promise<OpenAIClientResponse<CreateChatCompletionResponse>>} The chat completion response.
     * @private
     */
    private createChatCompletion;
    /**
     * Creates a completion request for the given prompt.
     * @param {CreateCompletionRequest} request The request to create the completion for.
     * @returns {Promise<OpenAIClientResponse<CreateCompletionResponse>>} The completion response.
     * @private
     */
    private createCompletion;
}
//# sourceMappingURL=OpenAIPlanner.d.ts.map